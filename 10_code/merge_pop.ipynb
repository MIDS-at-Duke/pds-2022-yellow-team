{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_pop_data(state_name):\n",
    "    '''\n",
    "    This function will merge the two population datasets together.\n",
    "    Input: state_name\n",
    "        state_name: the state name\n",
    "    return: a pandas dataframe with the merged population data\n",
    "    '''\n",
    "    # read in the data\n",
    "    all_2000_2009 = pd.read_csv('../00_source_data/US_Population/start_2000.csv', encoding='latin-1')\n",
    "    all_2010_2019 = pd.read_csv('../00_source_data/US_Population/start_2010.csv', encoding='latin-1')\n",
    "\n",
    "    # columns to keep\n",
    "    pop_col_2000_2009 = ['STNAME', 'CTYNAME', 'POPESTIMATE2000', 'POPESTIMATE2001', 'POPESTIMATE2002','POPESTIMATE2003', 'POPESTIMATE2004',\n",
    "                        'POPESTIMATE2005', 'POPESTIMATE2006','POPESTIMATE2007', 'POPESTIMATE2008', 'POPESTIMATE2009']\n",
    "    pop_col_2010_2019 = ['STNAME', 'CTYNAME', 'POPESTIMATE2010', 'POPESTIMATE2011', 'POPESTIMATE2012','POPESTIMATE2013', 'POPESTIMATE2014',\n",
    "                        'POPESTIMATE2015', 'POPESTIMATE2016','POPESTIMATE2017', 'POPESTIMATE2018', 'POPESTIMATE2019']\n",
    "\n",
    "    # filter the data\n",
    "    pop_2000_2009 = all_2000_2009[all_2000_2009['STNAME'] == state_name][pop_col_2000_2009]\n",
    "    pop_2010_2019 = all_2010_2019[all_2010_2019['STNAME'] == state_name][pop_col_2010_2019]\n",
    "\n",
    "    # rename the columns\n",
    "    pop_2000_2009.columns = ['STNAME', 'CTYNAME', '2000', '2001', '2002','2003', '2004','2005','2006', '2007', '2008', '2009']\n",
    "    pop_2010_2019.columns = ['STNAME', 'CTYNAME', '2010', '2011', '2012','2013', '2014','2015','2016', '2017', '2018', '2019']\n",
    "\n",
    "    assert pop_2000_2009.shape[0] == pop_2010_2019.shape[0]  # number of county should be the same\n",
    "    # merge two datasets\n",
    "    pop_2000_2019 = pd.merge(pop_2000_2009, pop_2010_2019, how = 'outer', on = ['STNAME', 'CTYNAME'])\n",
    "\n",
    "    # remove the aggregate population of the state\n",
    "    pop_2000_2019 = pop_2000_2019[pop_2000_2019['CTYNAME'] != state_name]\n",
    "\n",
    "    # convert columns to rows   \n",
    "    pop = pd.melt(pop_2000_2019, id_vars=['STNAME', 'CTYNAME'], var_name='YEAR', value_name='POPULATION')\n",
    "    assert pop.shape[0] == pop_2000_2019.shape[0] * (pop_2000_2019.shape[1]-2)  # number of rows should be the same\n",
    "    assert pop['YEAR'].nunique() == (pop_2000_2019.shape[1]-2)  # number of years should be the same\n",
    "    \n",
    "    return pop\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Florida and its reference states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AZ, CO, FL, LA, NV, SC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_az = merge_pop_data('Arizona')\n",
    "pop_co = merge_pop_data('Colorado')\n",
    "pop_fl = merge_pop_data('Florida')\n",
    "pop_la = merge_pop_data('Louisiana')\n",
    "pop_nv = merge_pop_data('Nevada')\n",
    "pop_sc = merge_pop_data('South Carolina')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "fl_shipment_pop = pd.concat([pop_az, pop_fl, pop_la, pop_sc])\n",
    "assert fl_shipment_pop.shape[0] == pop_az.shape[0] + pop_fl.shape[0] + pop_la.shape[0] + pop_sc.shape[0]  # make sure the number of rows is the same\n",
    "\n",
    "# write the data to csv\n",
    "fl_shipment_pop.to_csv('../20_intermediate_files/fl_shipment_pop.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "fl_death_pop = pd.concat([pop_co, pop_fl, pop_la, pop_nv])\n",
    "assert fl_death_pop.shape[0] == pop_co.shape[0] + pop_fl.shape[0] + pop_la.shape[0] + pop_nv.shape[0]  # make sure the number of rows is the same\n",
    "\n",
    "# write the data to csv\n",
    "fl_death_pop.to_csv('../20_intermediate_files/fl_death_pop.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Texas and its reference states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NY, OR, TX, WI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_ny = merge_pop_data('New York')\n",
    "pop_or = merge_pop_data('Oregon')\n",
    "pop_tx = merge_pop_data('Texas')\n",
    "pop_wi = merge_pop_data('Wisconsin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx_death_pop = pd.concat([pop_ny, pop_or, pop_tx, pop_wi])\n",
    "assert tx_death_pop.shape[0] == pop_ny.shape[0] + pop_or.shape[0] + pop_tx.shape[0] + pop_wi.shape[0]  # make sure the number of rows is the same\n",
    "\n",
    "# write the data to csv\n",
    "tx_death_pop.to_csv('../20_intermediate_files/tx_death_pop.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Washington and its reference states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AZ, CO, HI, NY, OK, OR, WA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_az = merge_pop_data('Arizona')\n",
    "pop_co = merge_pop_data('Colorado')\n",
    "pop_hi = merge_pop_data('Hawaii')\n",
    "pop_ny = merge_pop_data('New York')\n",
    "pop_ok = merge_pop_data('Oklahoma')\n",
    "pop_or = merge_pop_data('Oregon')\n",
    "pop_wa = merge_pop_data('Washington')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "wa_shipment_pop = pd.concat([pop_az, pop_co, pop_ny, pop_wa])\n",
    "assert wa_shipment_pop.shape[0] == pop_az.shape[0] + pop_co.shape[0] + pop_ny.shape[0] + pop_wa.shape[0]  # make sure the number of rows is the same\n",
    "\n",
    "# write the data to csv\n",
    "wa_shipment_pop.to_csv('../20_intermediate_files/wa_shipment_pop.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "wa_death_pop = pd.concat([pop_hi, pop_ok, pop_or, pop_wa])\n",
    "assert wa_death_pop.shape[0] == pop_hi.shape[0] + pop_ok.shape[0] + pop_or.shape[0] + pop_wa.shape[0]  # make sure the number of rows is the same\n",
    "\n",
    "# write the data to csv\n",
    "wa_death_pop.to_csv('../20_intermediate_files/wa_death_pop.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3ad933181bd8a04b432d3370b9dc3b0662ad032c4dfaa4e4f1596c548f763858"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
